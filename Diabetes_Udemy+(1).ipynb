{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0X-FWnNfN5L8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VS_f4lcDPFrs",
    "outputId": "7bc00925-9d84-4f14-eb96-084125a16995"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eTx0Bk-PO0ro",
    "outputId": "9530147c-2afc-447c-c869-ade71b7858fd"
   },
   "outputs": [],
   "source": [
    "%cd /content/drive/My Drive/Colab Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9bkencI0PU-a"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cnDeeg2JP5Fs",
    "outputId": "bedc5f39-58c1-4af3-b77a-2165a2dca8cb"
   },
   "outputs": [],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Nne4xcpQIPk"
   },
   "source": [
    "\n",
    "\n",
    "*   Pregnancies: Number of previous pregnancies\n",
    "*   Glucose: Plagma glucose concentration\n",
    "\n",
    "*   BloodPressure: Diastolic blood pressure\n",
    "*   SkinThickess: Skin fold thickness measured from the triceps\n",
    "\n",
    "\n",
    "*   Insulin: Blood serum insulin concentration\n",
    "*   BMI: Body Mass Index\n",
    "\n",
    "*   DiabetesPedigreeFunction: A summerized score that indicates the genetic predisposition of the patient for diabetes, as extrapolated from the patient's family record for diabetes\n",
    "*   Age: Age in years\n",
    "\n",
    "\n",
    "*   Outcome: The target variable we are trying to predict , 1 for patients that developed diabetes within 5 years of the initial measurement and 0 otherwise\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "rTf_Fv2JRNQ5",
    "outputId": "917a8d3d-5314-4577-f38f-954cff740510"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "df.hist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tacUf_MeWZxk"
   },
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "oeVR-lHfXpI2",
    "outputId": "0d9ab5f0-6327-4e68-a61c-cced19cd91a8"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# create a subplot of 3x3\n",
    "plt.subplots(3,3,figsize=(15,15))\n",
    "#plot a density plot for each variable\n",
    "# Plot a density plot for each variable\n",
    "for idx, col in enumerate(df.columns):\n",
    "    ax = plt.subplot(3,3,idx+1)\n",
    "    ax.yaxis.set_ticklabels([])\n",
    "    sns.distplot(df.loc[df.Outcome == 0][col], hist=False, axlabel= False, kde_kws={'linestyle':'-', 'color':'black', 'label':\"No Diabetes\"})\n",
    "    sns.distplot(df.loc[df.Outcome == 1][col], hist=False, axlabel= False, kde_kws={'linestyle':'--', 'color':'black', 'label':\"Diabetes\"})\n",
    "    ax.set_title(col)\n",
    "#Hide the 9th subplot (bottom right since there are only 8 plots)\n",
    "plt.subplot(3,3,9).set_visible(False)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ebI13eMqZLWi"
   },
   "source": [
    "100mg/dL\n",
    "\n",
    "*   Dash line is Diabetics\n",
    "*   Solid line is non-Diabetics\n",
    "\n",
    "\n",
    "150mg/dL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DWBH2f7BjmoV",
    "outputId": "715232e0-dcad-49f2-a343-e313b2d39979"
   },
   "outputs": [],
   "source": [
    "print(df.isnull().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "efzRaJPkkD6y",
    "outputId": "042b7876-644e-42b8-af56-e7529b048381"
   },
   "outputs": [],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HeSc1ilNkcLb",
    "outputId": "a3090c12-69df-40ca-efa0-a6085b08b372"
   },
   "outputs": [],
   "source": [
    "print(\"Number of rows with 0 values for each variable\")\n",
    "for col in df.columns:\n",
    "  missing_rows = df.loc[df[col]==0].shape[0]\n",
    "\n",
    "  print(col + \": \"+str(missing_rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aPPN-Zbtk5dB"
   },
   "source": [
    "There are several techniques to handle these missing values:\n",
    "\n",
    "\n",
    "*   Remove (discard) any rows with missing values\n",
    "*   Replace the missing values with the mean/median/mode of the non-missing values.\n",
    "\n",
    "\n",
    "*   Predict the actual values using a seperate machine learning model\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dYMRDivolcBm"
   },
   "outputs": [],
   "source": [
    "#Replace 0 value with NaN\n",
    "import numpy as np\n",
    "df['Glucose'] = df['Glucose'].replace(0,np.nan)\n",
    "df['BloodPressure'] = df['BloodPressure'].replace(0,np.nan)\n",
    "df['SkinThickness'] = df['SkinThickness'].replace(0,np.nan)\n",
    "df['Insulin'] = df['Insulin'].replace(0,np.nan)\n",
    "\n",
    "df['BMI'] = df['BMI'].replace(0,np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WfsT3XUsmLO_",
    "outputId": "f30e78fe-61d0-4c41-c078-97cc3ce3bb69"
   },
   "outputs": [],
   "source": [
    "print(\"Number of rows with 0 values for each variable\")\n",
    "for col in df.columns:\n",
    "  missing_rows = df.loc[df[col]==0].shape[0]\n",
    "\n",
    "  print(col + \": \"+str(missing_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4hqUOB0cmVRl"
   },
   "outputs": [],
   "source": [
    "# Replace Nan values with the mean of the non-missing values by using fillna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MXCmoiAPmfaB"
   },
   "outputs": [],
   "source": [
    "df['Glucose'] = df['Glucose'].fillna(df['Glucose'].mean())\n",
    "df['BloodPressure'] = df['BloodPressure'].fillna(df['BloodPressure'].mean())\n",
    "df['SkinThickness'] = df['SkinThickness'].fillna(df['SkinThickness'].mean())\n",
    "df['Insulin'] = df['Insulin'].fillna(df['Insulin'].mean())\n",
    "\n",
    "df['BMI'] = df['BMI'].fillna(df['BMI'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2NT19yawtZWO"
   },
   "source": [
    "The goal of data standardization is to transform the numeric variables so that each variable has zero mean and unit varianace.\n",
    "\n",
    "\n",
    "*   Insulin and DiabetesPedigreeFunction have vastly differennt scales. The maximum value for Insulin is 846 while the maximum value for DiabetesPedigreeFunction is only 2.42\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6QKowRlIuMzn",
    "outputId": "9c893138-11f0-4a11-a9d8-2571b56c0d30"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "df_scaled = preprocessing.scale(df)\n",
    "df_scaled = pd.DataFrame(df_scaled,columns=df.columns)\n",
    "df_scaled['Outcome'] = df['Outcome']\n",
    "df = df_scaled\n",
    "print(df.describe().loc[['mean','std','max'],].round(2).abs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wLH2NygtwCZY"
   },
   "source": [
    "\n",
    "\n",
    "1.   Training set: The neural network will be trained on this subset of the data\n",
    "2.   Validation set: This set of data allows us to perform hyperparameter tuning(That is, tuning the number of hidden layers) using an unbiased source of data\n",
    "1.   Testing set: The final evaluation of the neural network will be based on this subset of the data.\n",
    "The purpose of splitting the data into training, testing and validation sets is to avoid overfitting and to provide an unbiased source of data for evaluating performance\n",
    "\n",
    "*   If we allocate most of our data for training purposes, model performance will increase at the detriment of our ability to avoid overfitting.\n",
    "*   If we allocate most of our data for validation and testing purposes, model performance will decrease as there might be insufficient data for training.\n",
    "\n",
    "There are some steps:\n",
    "\n",
    "*   Original data is 1st spliited into training (80%) and testing (20%)\n",
    "*   Training set is 2nd splitted into training set, validation set and testing set.\n",
    "Splitting data must be done at random\n",
    "*   First, let's seperate the dataset into X(input features) and y(target variable)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K59EWgy3ySM-"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df.loc[:, df.columns != 'Outcome']\n",
    "y = df.loc[:, 'Outcome']\n",
    "# Split the data into training set(80%) and the testing set(20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "# Make a second split to create the final training set and the validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train,y_train,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G1zF-RsFSlUq"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ASvmxCIPSwex"
   },
   "source": [
    "\n",
    "\n",
    "*   The first hidden layer will have 32 nodes\n",
    "*   The input dimension will be 8 because there 8 columns in X_train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gZFaSnZDTIzi"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense # Add the first Hidden layer\n",
    "model.add(Dense(32, activation='relu', input_dim=8))\n",
    "model.add(Dense(16, activation='relu'))# Add the second hidden layer\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Be-hPa1NUr_7"
   },
   "source": [
    "There are three different parameters we need to define for the training process\n",
    "\n",
    "*   Optimizer: Let's use the adam optimizer, whihc is a popular optimizer in Keras. For most datasets, the adam optimizer will work well without much tuning\n",
    "*   Loss function: We will use binary_crossentropy as our loss function since the problem at hand is a binary classification problem.\n",
    "\n",
    "*   Metrics: We will use accuracy (that is the percentage of correctly classified samples) as our evaluation metric.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-13GS3_dVchc"
   },
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y-aHFbrvXY01",
    "outputId": "afee1911-a1f8-49da-b03b-ead40610e9ee"
   },
   "outputs": [],
   "source": [
    "#Train the model for 200 epochs\n",
    "model.fit(X_train,y_train,epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VzkCaBxBalI0",
    "outputId": "c0ed54a2-c44e-48c2-9491-ae46237bcb46"
   },
   "outputs": [],
   "source": [
    "scores = model.evaluate(X_train,y_train)\n",
    "print(\"Training Accuracy: %.2f%%\\n\" % (scores[1]*100))\n",
    "scores = model.evaluate(X_test,y_test)\n",
    "print(\"Testing Accuracy: %.2f%%\\n\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q_fDEFRfEJe_"
   },
   "source": [
    "\n",
    "\n",
    "*   True negative: Actual class is negative (no diabetes), and the model predicted negative (no diabetes)\n",
    "*   False positive : Actual class is negative (no diabetes), but the model predicted positive (diabetes)\n",
    "\n",
    "\n",
    "*   False negative: Actial class is positive (diabetes) but the model predicted negative (no diabetes)\n",
    "*   True positive: Actual class is positve (diabetes), and the model predicted positive (diabetes)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "dFdv2NsvE2dq",
    "outputId": "cc4d8fb4-a7b2-4c2b-cebc-1492dbbf400f"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "y_test_pred = model.predict_classes(X_test)\n",
    "c_matrix = confusion_matrix(y_test,y_test_pred)\n",
    "ax = sns.heatmap(c_matrix, annot=True, xticklabels=['No Diabetes','Diabetes'], yticklabels=['No Diabetes','Diabetes'], cbar= False, cmap='Blues')\n",
    "ax.set_xlabel(\"Prediction\")\n",
    "ax.set_ylabel(\"Actual\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v5Qy9FTaHVOj"
   },
   "source": [
    "\n",
    "\n",
    "*   True positive rate (TPR) = True positive / (True positive + false negative)\n",
    "*   False positive Rate (FPR) = False positive /(true Negative + False Positive)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kkL30TEUH4Wu"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_test_pred_probs = model.predict(X_test)\n",
    "FPR,TPR, _= roc_curve(y_test,y_test_pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "-QqqKKyOIbPa",
    "outputId": "5bb47761-db8a-44c0-b3dd-e06fa75ab47d"
   },
   "outputs": [],
   "source": [
    "plt.plot(FPR,TPR)\n",
    "plt.plot([0,1],[0,1],'--',color='black')#diagonal line\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "\n",
    "plt.ylabel('True Positive Rate')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Diabetes Udemy.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
